Cache一致性简介
###################

:date: 2015-10-11 15:30
:modified: 2015-10-11 18:50
:slug: intro-of-cache-coherency
:category: 技术
:tags: Cache
:summary: 最近在课外学习过程中，了解到了很多性能优化（或者说是程序设计的技巧）的点。这里先简单针对CPU缓存，做些基础知识的介绍。

直接进入主题，先看一段很普通的代码：

.. code-block:: cpp
    :linenos:

    #include <pthread.h>
    #include <stdio.h>

    pthread_barrier_t barrier;

    //三个线程，在每个线程中，分别对以下任一一个counter变量元素进行累加
    int counter1[16];
    int counter2[16];
    int counter3[16];

    void* thr1(void*) {
        pthread_barrier_wait(&barrier);

        for (int i = 0; i < 100000; i++) {
            counter1[0]++; 
        }

        return NULL;
    }

    void* thr2(void*) {
        pthread_barrier_wait(&barrier);

        for (int i = 0; i < 100000; i++) {
            counter2[0]++; //方案1
            //counter1[1]++; //方案2
        }

        return NULL;
    }

    void* thr3(void*) {
        pthread_barrier_wait(&barrier);

        for (int i = 0; i < 100000; i++) {
            counter3[0]++; //方案1
            //counter1[2]++; //方案2
        }

        return NULL;
    }

    int main() {
        pthread_barrier_init(&barrier, NULL, 3);
        pthread_t pids[3];

        timespec time1, time2;
        clock_gettime(CLOCK_REALTIME, &time1);
        pthread_create(&pids[0], NULL, thr1, NULL);
        pthread_create(&pids[1], NULL, thr2, NULL);
        pthread_create(&pids[2], NULL, thr3, NULL);

        for (int i = 0; i < 3; i++) {
            pthread_join(pids[i], NULL);
        }

        clock_gettime(CLOCK_REALTIME, &time2);
        printf("%ld\n", time2.tv_sec * 1000000000 + time2.tv_nsec - 
                (time1.tv_sec * 1000000000 + time1.tv_nsec));

        pthread_barrier_destroy(&barrier);
        return 0;
    }

编译运行结果：方案1：1703734；方案2：34322528，我的环境中，比方案1性能差了约20倍。

乍一看，仅仅一个变量的区别，为何结果会相差如此大。这里就进入了CPU Cache一致性的问题。这里一步步介绍。

1.  **缓存（Cache）**

在现代CPU架构中，CPU的读写单元由于没有和内存连接的管脚一般都无法和内存通信，对于内存的访问几乎都需要通过层层的缓存来实现，如一级缓存、二级缓存……而一级缓存只能和二级缓存来做通信。

缓存内部是按照段（line）组织的，每一段是一个固定大小（一般为32、64或128）的存储空间且都知道映射到的下一次存储（缓存或内存）的某个地址区间。

当CPU遇到一条读指令时，会将对应的内存地址传给一级缓存（准确的说是一级数据缓存。现在的CPU架构普遍对一级缓存进行了划分：数据缓存、指令缓存）。一级缓存则检查它是否含有这个内存地址对应的缓存段（CacheLine），如果没有，它会把整个缓存段从下一级存储（内存或二级缓存，依次类推）中加载进来（加载整个缓存段的原因主要是根据数据访问的空间局部性原理）。当缓存段被加载到缓存后，读操作则可以继续进行。读操作看起来比较简单，所有的缓存都是同样的原理： `基本定律：在任意时刻，任意级别缓存中的缓存段的内容，等同于它对应的内存中的内容。`

而一旦有了写操作，问题就复杂起来了。这里有两种写模式：直写（write-through）和回写（write-back）。直接比较简单：透过本级缓存，将数据直接写到下级缓存或内存汇总。如果对应的段被缓存了，则同时更新缓存中的内容（甚至直接丢弃），就这么简单。这也遵守前面的原理：缓存中的段永远和它对应的内存内容匹配。回写模式就有点复杂，缓存不会立即把写操作传递到下一级，而是仅修改本级缓存中的数据，并且把对应的缓存段标记为“脏”段。脏段会触发回写，也就是把里面的内容写到对应的内存或下一级缓存中。回写后，脏段又变“干净”了。当一个脏段被丢弃的时候，总是先要进行一次回写。回写所遵循的规律有点不同。 `回写定律：当所有的脏段被回写后，任意级别缓存中的缓存段的内容，等同于它对应的内存中的内容。`  回写模式的定律中，没有“在任意时刻”这个修饰语，代之以弱化一点的条件：要么缓存段的内容和内存一致（如果缓存段是干净的话），要么缓存段中的内容最终要回写到内存中（对于脏缓存段来说）。

直接模式更简单，但是如果系统大多数缓存在回写模式下工作，那么系统经常可以写一大片内存而不是频繁的小内存写入，这样，回写的效率比直写高的多。

需要说明的是，这里忽略掉了其他的一些概念，如缓存关联性（cache associativity），缓存组（cache sets），非对齐的访问（unaligned access）等，感兴趣的话可以单独查询资料，这里已经给出对应的关键词。

2.  **一致性协议（Coherency protocols）**

如果系统只有一个CPU核在工作，都没问题，如果多个核一起工作，且每个核有自己独立的缓存，那么就有问题：如果一个核缓存段中对应的内存数据被另外一个核修改了，会发生什么？

如果答案是什么也不会发生，那么就会很悲剧，我们希望的是拥有多组缓存的时候，保持数据同步。而内存在各个CPU缓存之间无法做到与生俱来的同步。

这里需要强调的是，这个问题的根据在于多组缓存，而不是多个CPU核。或许可以这样解决，多个CPU核共用一组缓存：只有一块一级缓存、一块二级缓存……。在每一个指令周期，只有一个CPU能通过一级缓存做内存操作，运行它的指令。这个方案可以解决问题。但是性能太慢了。因为这些处理器的时间都花在排队等待使用一级缓存了（并且处理器会做大量的这种操作，至少每个读写指令都要做一次）。这里说明这个是为了说明明了问题不是由多核引起的，而是由多组缓存引起的。而使用多组缓存还希望可以像使用一组缓存一样，缓存一致性协议就是为了做到这一点而设计的。就像名称所暗示的那样，这类协议就是要使多组缓存的内容保持一致。

缓存一致性协议有多种，但是日常处理的大多数计算机设备使用的都属于“窥探（snooping）”协议，（还有一种叫“基于目录的（directory-based）”协议，这种协议的延迟性较大，但是在拥有很多个处理器的系统中，它有更好的可扩展性。）“窥探”背后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道，而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。

在直写模式下，这是很直接的，因为写操作一旦发生，它的效果马上会被“公布”出去。但是如果混着回写模式，就有问题了。因为有可能在写指令执行过后很久，数据才会被真正回写到物理内存中——在这段时间内，其他处理器的缓存也可能会傻乎乎地去写同一块内存地址，导致冲突。在回写模型中，简单把内存写操作的信息广播给其他处理器是不够的，我们需要做的是，在修改本地缓存之前，就要告知其他处理器。搞懂了细节，就找到了处理回写模式这个问题的最简单方案，我们通常叫做MESI协议（译者注：MESI是Modified、Exclusive、Shared、Invalid的首字母缩写，代表四种缓存状态）。

*其实，到了这里，本文开头的现象就有了解答，测试机器上的cache line是64字节，方案2中，每次操作，均会对缓存的cache line发生写操作，而这些写操作需要在不同的缓存组之间进行同步，当然这个比不同步（方案1中的操作不涉及同一cache line的写操作）要慢，且慢的多（在我的环境中，运行结果差了约20倍）。当然，这里要知道了问题的原因后，继续深入介绍相关的原理。*

3.  **MESI**

MESI衍生了一系列紧密相关的一致性协议。这里介绍原生的MESI协议：MESI是四种缓存段状态的首字母缩写，任何多核系统中的缓存段都处于这四种状态之一。这里将以相反的顺序逐个介绍，因为这个顺序更合理。

- 失效（Invalid）缓存段，要么已经不在缓存中，要么它的内容已经过时。为了达到缓存的目的，这种状态的段将会被忽略。一旦缓存段被标记为失效，那效果就等同于它从来没被加载到缓存中。
- 共享（Shared）缓存段，它是和主内存内容保持一致的一份拷贝，在这种状态下的缓存段只能被读取，不能被写入。多组缓存可以同时拥有针对同一内存地址的共享缓存段，这就是名称的由来。
- 独占（Exclusive）缓存段，和S状态一样，也是和主内存内容保持一致的一份拷贝。区别在于，如果一个处理器持有了某个E状态的缓存段，那其他处理器就不能同时持有它，所以叫“独占”。这意味着，如果其他处理器原本也持有同一缓存段，那么它会马上变成“失效”状态。
- 已修改（Modified）缓存段，属于脏段，它们已经被所属的处理器修改了。如果一个段处于已修改状态，那么它在其他处理器缓存中的拷贝马上会变成失效状态，这个规律和E状态一样。此外，已修改缓存段如果被丢弃或标记为失效，那么先要把它的内容回写到内存中——这和回写模式下常规的脏段处理方式一样。

如果把以上这些状态和单核系统中回写模式的缓存做对比，就会发现I、S和M状态已经有对应的概念：失效/未载入、干净以及脏的缓存段。所以这里的只有E状态是新引入的，代表独占式访问。这个状态解决了“在我们开始修改某块内存之前，我们需要告诉其他处理器”这一问题：只有当缓存段处于E或M状态时，处理器才能去写它，也就是说只有这两种状态下，处理器是独占这个缓存段的。当处理器想写某个缓存段时，如果它没有独占权，它必须先发送一条“我要独占权”的请求给总线，这会通知其他处理器，把它们拥有的同一缓存段的拷贝失效（如果它们有的话）。只有在获得独占权后，处理器才能开始修改数据——并且此时，这个处理器知道，这个缓存段只有一份拷贝，在我自己的缓存里，所以不会有任何冲突。

反之，如果有其他处理器想读取这个缓存段（我们马上能知道，因为我们一直在窥探总线），独占或已修改的缓存段必须先回到“共享”状态。如果是已修改的缓存段，那么还要先把内容回写到内存中。

MESI协议是一个合适的状态机，既能处理来自本地处理器的请求，也能把信息广播到总线上。这里强调两点：

- 在多核系统中，读取某个缓存段，实际上会牵涉到和其他处理器的通讯，并且可能导致它们发生内存传输。写某个缓存段需要多个步骤：在你写任何东西之前，你首先要获得独占权，以及所请求的缓存段的当前内容的拷贝（所谓的“带权限获取的读（Read For Ownership）”请求）。

- 尽管我们为了一致性问题做了额外的工作，但是最终结果还是非常有保证的。即它遵守 `MESI定律：在所有的脏缓存段（M状态）被回写后，任意缓存级别的所有缓存段中的内容，和它们对应的内存中的内容一致。此外，在任意时刻，当某个位置的内存被一个处理器加载为独占缓存段时（E状态），那它就不会再出现在其他任何处理器的缓存中。`

注意，这其实就是回写定律加上独占规则而已。其实MESI协议或多核系统的存在根本没有弱化我们现有的内存模型。

MESI协议的扩展包括“O”（Owned）状态，它和E状态类似，也是保证缓存间一致性的手段，但它直接共享脏段的内容，而不需要先把它们回写到内存中（“脏段共享”），由此产生了MOSEI协议。还有MERSI和MESIF，这两个名字代表同一种思想，即指定某个处理器专门处理针对某个缓存段的读操作。当多个处理器同时拥有某个S状态的缓存段的时候，只有被指定的那个处理器（对应的缓存段为R或F状态）才能对读操作做出回应，而不是每个处理器都能这么做。这种设计可以降低总线的数据流量。当然你可以同时加入R/F状态和O状态，或者更多的状态。这些都属于优化，没有一种会改变基本定律，也没有一种会改变MESI协议所确保的结果。

这里MESI及其扩展保证的不是基本一致，不是“写入一会儿后才能保持一致”——而是完全的一致。从这个层面上说，除非硬件有问题，内存的状态总是一致的。用技术术语来说，MESI以及它的衍生协议，至少在原理上，提供了完整的顺序一致性（sequential consistency）。

4.  **缓存段竞争**

在日常的运算中，部分内存访问操作实际上会无法命中缓存，从而只能从内存中加载。一旦有些缓存段因为长时间不被访问而被丢弃，就要开始把它的内容回写（write-back）到内存中。所有这些事件都会导致总线上（以及内存中）发生通讯流量。而总线和内存的带宽是有限的，当容量饱和时，系统就变慢了。

而且，一旦我们在多核系统中运行多线程程序，总线上就会产生额外的通讯流量来保证缓存一致性，因为各个处理器都会不断地同步它们所看到的内存内容。如果每个线程都在自己独立的内存空间里工作，那么这种流量不会很大。如果每块内存只会被一个处理器使用，那么根本无需同步，而且我们可以很容易获取这些内存对应的缓存段的独占权，不会引起其他处理器上的缓存段失效。这也是方案1中的情形。

相反，如果两个或多个处理器频繁地访问相同的缓存段，那么这些缓存段的内容必须保持同步。如果想更新其中一个缓存段的内容，必须先获得独占权，这意味着其他所有处理器必须先丢弃它们缓存中的同一缓存段的拷贝。这带来的结果是，下一次有另外一个处理器要访问这个缓存段，它的内容必须先通过总线来加载。所以结果就是缓存失效率（对于其他处理器来说）和总线上额外的通讯流量都增加了。这种多个处理器访问一个频繁被更新的缓存段的现象，叫做“缓存（段）竞争”。如果你想在多个处理器共用内存的环境中拖慢一个并行的程序，这也许是最简单的方法。

要产生缓存段竞争，需要多个处理器频繁访问同一缓存段，并且其中部分的访问是写操作。私有数据（只会被一个线程访问的缓存段）从来不是问题。不变的（immutable）数据（只被写一次，其后到生命期结束都不会被修改）也不是问题。麻烦的是那些既被线程共享，又可变的数据：处理这些数据需要大量的通讯工作来使各个处理器看到的内存内容保持一致。这种通讯代价很大——并且随着处理器数量的增多，开销会越来越大。

一旦有第二个处理器在读同一个缓存段，开销就会暴增。同时读取这个缓存段的处理器越多，开销就越大，而如果同时还有处理器在写这个缓存段，那么效果更甚。为保证缓存一致性而产生的真正开销跟具体的上下文有很大关系。在这里做的只是对保证缓存一致性而产生的开销有一个粗略的直观感受（即：它是无法忽略不计的）。

其中有一些通讯流量是不必要的。比如，由于缓存一致性的最小颗粒度是段，很多不必要的同步开销是可以简化的，因为不同类型的数据——不可变的、私有的和共享的——在同一缓存段中交错分布（或者类似地，因为一个缓存段中只保存了多个线程各自的私有数据）。这种现象叫做“假共享”。幸运的是，这种问题可以简单通过性能评估程序来定位，通过重新组织内存数据（可能通过填充的方式，确保不同类型的数据不放在同一缓存段）的方法，可以相对直接地修复它，或者直接移除一些捣乱的数据。

经此过滤下来的就是真正的竞争了——竞争访问共享数据。这包括了真正共享的可变数据结构，以及某些元数据（metadata），比如锁和其他同步对象。准确地说，这种竞争运行得有多流畅，取决于数据在内存中的具体布局，以及使用什么操作来访问它。

一般来说，要写出在多核处理器上具有良好可伸缩性（scalable）的代码，方法就是尽可能避免竞争，如果不能避免，则使所有竞争都尽可能快速通过。完善地考虑竞争问题，理解缓存一致性的工作原理（至少要大致上），理解处理器为了保证缓存一致性而需要交换什么信息，理解这种通讯何时会发生，这毫无疑问，是非常重要的。