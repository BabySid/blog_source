链接库的介绍
#######################

:date: 2015-08-23 16:30
:slug: intro-of-library
:category: 技术
:tags: 编译;链接;动态库;静态库
:summary: 有时候在链接的时候回遇到 `undefined reference error` 等错误，在这里将从编译开始逐步介绍库的原理以及使用的注意事项。

1. **从程序到可执行文件**

- 从hello world说起

.. code-block:: c
    :linenos:

    #include <stdio.h>

    int main() { 
        printf("hello world\n"); 
        return 0; 
    } 

上面这一段程序任何一个学过C语言的同学都是闭着眼睛都可以写出来，但是对于将这样一个源代码编译成为一个可执行文件的过程却不一定有所了解。上面的程序如果要编译，很简单：

.. code-block:: shell
    :linenos:

    gcc hello.c

然后 `./a.out` 就可以运行，但是在这个简单的命令后面隐藏了许多复杂的过程。一般来说，可以把这样的过程分成4个：预编译、编译、汇编和链接。

- 预编译
    这个过程包括了下面的步骤：

    1. 宏定义展开，所有的#define 在这个阶段都会被展开
    #. 预编译命令的处理，包括#if #ifdef 一类的命令
    #. 展开#include 的文件，像上面hello world 中的stdio.h ， 把stdio.h中的所有代码合并到hello.c中
    #. 去掉注释

gcc的预编译 采用的是预编译器cpp, 我们可以通过-E参数来看预编译的结果，如：

.. code-block:: shell
    :linenos:

    gcc -E hello.c -o hello.i

生成的 `hello.i` 就是经过了预编译的结果。在预编译的过程中不会太多的检查与预编译无关的语法( `#ifdef` 之类的还是需要检查，`#include` 文件路径需要检查)，但是对于一些诸如 `;` 漏掉的语法错误，在这个阶段都是看不出来的。写过makefile的人都知道，我们需要加上 `-Ipath` 一系列的参数来标示gcc对头文件的查找路径。

小提示：

1. 在一些程序中由于宏的原因导致编译错误，可以通过-E把宏展开再检查错误，这个在编写PHP扩展、python扩展这些大量需要使用宏的地方对于查错误很有帮助。
#. 如果在头文件中，`#include` 的时候带上路径在这个阶段有时候是可以省不少事情，比如 `#include` ，这样在gcc的-I参数只需要指定一个路径，不会由于不小心导致文件名正好相同出现冲突的麻烦事情。
#. 不过个人认为所有的 `#include` 都应该是尽量采用从svn根路径下开始写完整路径名的方式进行预编译的过程，当然带路径的方式要多写一些代码,也是麻烦的事情。路径由外部指定相对也会灵活一些。所以在实际编写中，建议库的发布尽量包含库路径（如：include/libxxx。则include的时候则写为 `libxxx/xxx.h`)作为一种减少冲突的方法。

- 编译
    这个过程才是进行语法分析和词法分析的地方，他们将我们的C/C++代码翻译成为汇编代码，这也是一个编译器最复杂的地方。使用命令

.. code-block:: shell
    :linenos:

    gcc -S hello.i -o hello.s

可以看到gcc编译出来的汇编代码，现代gcc编译器一般是把预编译和编译合在一起，使用 `cc1` 程序来完成这个过程。所以有时候在编译大文件的时候可以用top命令看一个cc1的进程一直在占用时间，这个时候就是程序在执行编译过程。后面提到的编译过程都是指 `cc1` 的处理包括了预编译与编译。

- 汇编
    现在C/C++代码已经成为汇编代码了，直接使用汇编代码的编译器把汇编变成机器码（注意还不是可执行的)。

.. code-block:: shell
    :linenos:

    gcc -c hello.c -o hello.o

这里的 `hello.o` 就是最后的机器码，如果作为一个 `静态库` 到这里可以所已经完成了，不需要后面的过程。对于静态库的.a文件其实是多个.o 通过ar命令打包起来的，仅仅是为了方便使用，抛开.a直接使用.o也是一样的。

小提示:

1. gcc采用 `as` 进行汇编的处理过程，as由于接收的是gcc生成的标准汇编, 在语法检查上存在不少缺陷，如果是我们自己写的汇编代码给as去处理，经常会出现很多莫名奇妙的错误。

- 链接
    链接的过程，本质上来说是一个把所有的机器码文件组合成一个可执行的文件。上面汇编的结果得到一个.o文件，但是这个.o要生成二执行文件只靠它自己是不行的，它还需要一堆辅助的机器码，帮它处理与系统底层打交道的事情。

.. code-block:: shell
    :linenos:

    gcc -o hello hello.o 

这样就把一个.o文件链接成为了一个二进制可执行文件。我们提供的各种库头文件在编译期使用。到了链接期就需要用 `-l, -L` 的方式来指定我们到底需要哪些库。对于glibc中的strlen之类常用的东西编译器会帮助你去加上，不需要手动指定。这个地方也是本文讨论的重点, 在后面会有更详细的说明。

小提示:

1. 某些程序在编译的时候会出现 `linker input file unused because linking not done` 的提示（虽然gcc不认为是错误，这个提示还是会出现的），这里就是把编译和链接使用的参数搞混了，比如：

.. code-block:: shell
    :linenos:

    g++ -c hello.cpp -I../../xxxx/include -L../../xxxx/lib/ -lxxxx

这样的写法就会导致上面的提示，因为在编译的过程中是不需要链接的，它们两个过程其实是独立的。

2. **静态链接**

- 链接的过程
    这里先介绍一下，其实链接做的工作分两块: 符号解析和重定位：

a. 符号解析

符号包括了我们的程序中的被定义和引用的函数和变量信息，在命令行上使用 `nm ./a.out` 可以把在二进制目标文件中符号表输出。

.. code-block:: shell
    :linenos:

    0000000000601034 B __bss_start
    0000000000601034 b completed.6333
    0000000000601030 D __data_start
    0000000000601030 W data_start
    0000000000400470 t deregister_tm_clones
    00000000004004e0 t __do_global_dtors_aux
    0000000000600e18 t __do_global_dtors_aux_fini_array_entry
    00000000004005d8 R __dso_handle
    0000000000600e28 d _DYNAMIC
    0000000000601034 D _edata
    0000000000601038 B _end
    00000000004005c4 T _fini
    0000000000400500 t frame_dummy
    0000000000600e10 t __frame_dummy_init_array_entry
    0000000000400710 r __FRAME_END__
    0000000000601000 d _GLOBAL_OFFSET_TABLE_
                     w __gmon_start__
    00000000004003e0 T _init
    0000000000600e18 t __init_array_end
    0000000000600e10 t __init_array_start
    00000000004005d0 R _IO_stdin_used
                     w _ITM_deregisterTMCloneTable
                     w _ITM_registerTMCloneTable
    0000000000600e20 d __JCR_END__
    0000000000600e20 d __JCR_LIST__
                     w _Jv_RegisterClasses
    00000000004005c0 T __libc_csu_fini
    0000000000400550 T __libc_csu_init
                     U __libc_start_main@@GLIBC_2.2.5
    0000000000400530 T main
                     U puts@@GLIBC_2.2.5
    00000000004004a0 t register_tm_clones
    0000000000400440 T _start
    0000000000601038 D __TMC_END__

当然上面由nm输出的符号表可以通过编译命令去除，让人不能直接看到。链接器解析符号引用的方式是将每一个引用的符号与其它的目标文件(.o)的符号表中一个符号的定义联系起来，对于那些和引用定义在相同模块的本地符号（注：static修饰的），编译器在编译期就可以发现问题，但是对于那些全局的符号引用就比较麻烦了。下面来看一个最简单程序：

.. code-block:: cpp
    :linenos:

    /*hello.cpp*/

    int foo();

    int main() {
        foo(); 
        return 0; 
    } 

采用下面的方式进行编译：

.. code-block:: shell
    :linenos:

    g++ -c hello.cpp
    g++ -o hello hello.o

第一步正常结束，并且生成了hello.o文件，到第二步的时候报了如下的错误：

.. code-block:: shell
    :linenos:

    hello.o: In function `main':
    hello.cpp:(.text+0x5): undefined reference to `foo()'
    collect2: error: ld returned 1 exit status

由于foo是全局符号，在编译的时候不会报错，等到链接的时候，发现没有找到对应的符号，就会报出上面的错误。但是如果我们把上面的写法改成下面这样：

.. code-block:: cpp
    :linenos:

    /*hello.cpp*/

    static int foo(); //注意这里的static

    int main() {
        foo(); 
        return 0; 
    } 

运行 `g++ -c hello.cpp` ，马上就报以下错误：

.. code-block:: shell
    :linenos:

    hello.cpp:1:12: warning: ‘int foo()’ used but never defined [enabled by default]
    static int foo();
               ^

在编译器就发现foo无法生成目标文件的符号表，马上报错，对于一些本地使用的函数使用static一方面可以避免符号污染，另一方面也可以让编译器尽快的发现错误。
一般基础库提供的都是一系列的.a文件，这些.a文件其实是一批的目标文件(.o)的打包结果。这样的目的是可以方便的使用已有代码生成的结果，一般情况下是一个 `.c/.cpp` 文件生成一个.o文件。如果不提供.a，那么在编译的时候如果带上一堆的.o文件显的很不方便，如：

.. code-block:: shell
    :linenos:

    g++ -o hello hello.cpp a.o b.o c.o

这样大量的使用.o也很容易出错，在linux下使用 `archive` 来讲这些.o存档和打包。所以我们就可以把编译参数写成：

.. code-block:: shell
    :linenos:

    g++ -o hello hello.cpp ./libxxx.a

我们可以使用 `./libxxx.a` 直接使用 `libxxx.a` 这个库，不过gcc提供了另外的方式来使用：

.. code-block:: shell
    :linenos:

    g++ -o hello hello.cpp -L./ -lxxx

-L指定需要查找的库文件的路径，-l选择需要使用的库名字，不过库的名字需要用 `lib+name` 的方式命名，才会被gcc认出来。不过上面的这种方式存在一个问题就是不区分动态库和静态库，这个问题在后面介绍动态库的时候还会提到。
当存在多个.a并且在库之间也存在依赖关系，这个时候情况就比较复杂。如果我们要使用liba.a，liba,a又依赖libb.a， 这个时候需要写成类似下面的形式：

.. code-block:: shell
    :linenos:

    g++ -o hello hello.cpp -Lpath/of/liba -Lpath/of/libb -la -lb

-lb需要写在-la的后面，这是由于在默认情况对于符号表的解析和查找工作是由后往前（内部实现是一个类似堆栈的尾递归），所以当所使用的库本身存在依赖关系的时候，越是基础的库就越是需要放到后面。否则如果上面把 `-la -lb` 的位置换一下，可能就会出现 `undefined reference to　xxx` 的错误。当然gcc提供了另外的方式的来解决这个问题：

.. code-block:: shell
    :linenos:

    g++ -o hello hello.cpp -Lpath/of/liba -Lpath/of/libb -Xlinker "-(" -la -lb -Xlinker "-)"

可以看到我们需要的库被 `-Xlinker "-("` 和 `-Xlinker "-)"` 　包含起来，gcc在这里处理的时候会循环自动查找依赖关系，不过这样的代价就是延长gcc的编译时间，如果使用的库非常的多时候，对编译的耗时影响还是非常大。
-Xlinker有时候也简写成 `-Wl, `，它的意思是它后面的参数是给链接器使用的。`-Xlinker` 和 `-Wl` 的区别是一个后面跟的参数是用空格，另一个是用 `,` 。

我们通过nm命令查看目标文件，可以看到类似下面的结果：

.. code-block:: shell
    :linenos:

    #nm hello.o
    0000000000000000 T main
                     U _Z3foov

其中用 `U` 标示的符号 `_Z3foov` （其实是foo），表示在hello.o中没有找到 `foo` 函数。在链接的时候，链接器就会去其他的目标文件中查找 `_Z3foov` 的符号。

小提示：

1. 编译的时候采用 `-Lxxx -lyyy` 的形式使用库，-L和-l这个参数并没有配对的关系，一些Makefile是为了维护方便把它们写成配对的形式。其实完全可以写成　`-Lpath1, -Lpath2, -Lpath3, -lxxx -lyyy` 这样的形式。
#. 在具体链接的时候，gcc是以.o文件为单位，编译的时候如果写　`g++ -o hello hello.cpp libx.o` ，那么无论hello.cpp中是否使用到libx.o，libx.o中的所有符号都会被载入到hello函数中。但是如果是针对.a，写成 `g++ -o hello hello.cpp -L./ -lx` ，这个时候gcc在链接的时候只会链接有被用到的.o到hello中, 如果出现libx.a中的某个.o文件中没有任何一个符号被hello用到，那么这个.o就不会被链接到hello中。
#. gcc编译.c文件的时候和g++有一个不一样的地方，就是在g++中对于一个函数必须要先定义在再使用，比如上面的例子中需要先定义foo()才能被使用，但对于gcc编译的.c（如果是.cpp会自动换成C++编译）文件，可以不需要先定义而直接使用。但这样会出现问题，如果没有其他地方使用和这个函数同名的函数那么链接的时候会找不到这个函数。但是如果碰巧在另外的地方存在一个同名函数，那么链接的时候就会被直接连接到这个函数上，万一使用的时候偏偏传入参数或返回值的类型不对，那么这个时候就可能出现莫名奇妙的错误。不过还是可以用 `-Wmissing-declarations` 参数打开这个检查。

b. 重定位

经过上面的符号解析后，所有的符号都可以找到它所对应的实际位置（U表示的符号找到具体的实际位置）。as汇编生成一个目标模块的时候，它不知道数据和代码在最后具体的位置，同时也不知道任何外部定义的符号的具体位置，所以as在生成目标代码的时候，对于位置未知的符号，它会生成一个重定位表目，告诉链接器在将目标文件合并成可执行文件时候如何修改地址成最终的位置。

- g++和gcc
    采用gcc和g++在编译的时候产生的符号有所不同。

在C++中由于要支持函数重载，命名空间等特性，g++会把函数＋参数（可能还有命名空间），把函数命变成一个特殊并且唯一的符号名。例如：

.. code-block:: cpp
    :linenos:

    int foo(int a);

在gcc编译后，在符号表中的名字就是函数名foo, 但是在g++编译后名字可能就变成了 `_Z3fooi` ，我们可以使用 `c++filt` 命令把一个符号还原成它原本的样子，比如：

.. code-block:: shell
    :linenos:

    c++filt _Z3fooi 

运行的结果可以得到 `foo(int)` 。

由于在C++和纯C环境中，符号表存在不兼容问题，Ｃ程序不能直接调用C++编译出来的库，C++程序也不能直接调用C编译出来的库。为了解决这个问题C++中引入了　`extern "C"`　的方式：

.. code-block:: cpp
    :linenos:

    extern "C" int foo(int a);

这样在用g++编译的时候，c++的编译器会自动把上面的 `int foo(int a)` 当做C的接口进行符号转化。这样在纯C里面就可以认出这些符号。不过这里存在一个问题，`extern "C"` 是C++支持的，gcc并不认识，所有在实际中一般采用下面的方式使用：

.. code-block:: cpp
    :linenos:

    #ifdef __cplusplus 
    extern "C" { 
    #endif
            
    int foo(int a);
            
    #ifdef __cplusplus 
    } 
    #endif 

这样这个头文件中的接口即可以给gcc使用也可以给g++使用，当然在 `extern "C" { }` 中的接口是不支持重载，默认参数等特性的。

在64位编译环境中如果有gcc的程序使用上面方式g++编译出来的库，需要加上 `-lstdc++` ，这是因为对于64位环境下g++编译出来的库，需要使用到一个　`__gxx_personality_v0`　的符号，它所在的位置是 `/usr/lib64/libstdc++.so.6` （C++的标准库iostream都在里面，C++程序都需要的）。 但是在32位2.96 g++编译器中是不需要 `__gxx_personality_v0` ，所有编译可以不加上 `-lstdc++` 。

小提示：

1. 在linux gcc 中，只有在源代码使用.c做后缀，并且使用gcc编译才会被编译成纯C的结果，其他情况像g++编译.c文件，或者gcc编译.cc、.cpp文件都会被当作C++程序编译成C++的目标文件，gcc和g++唯一的不同在于gcc不会主动链接 `-lstdc++` 。
2. 在 `extern "C" { }` 中如果存在默认参数的接口，在g++编译的时候不会出现问题，但是gcc使用的时候会报错。因为对于函数重载，接口的符号表还是和不用默认参数的时候是一样的。

- 编译器版本问题
    采用gcc和g++在编译的时候产生的符号有所不同。有些时候会发现如果64位机器上的32位程序运行出core, 把core文件放到开发机上进行调试会看到出现在glibc的动态库的函数和core在一些很奇怪的位置，根本不是我们程序中调用的位置，这里很重要的原因就在于动态库的版本不一样。

小提示：
1. 基础库和二进制程序采用的gcc/g++保持一致，且版本保持一致。包括32/64位。

- 符号表冲突
    我们在编译程序的时候时常会遇到类似于下述的错误：

.. code-block:: shell
    :linenos:

    multiple definition of 'foo()' 

这些错误的产生都是由于所使用的.o文件中存在了相同的符号造成的。如：

.. code-block:: cpp
    :linenos:

    //libx.cpp
    int foo() { return 30; }

    //liby.cpp
    int foo() { return 20; } 

将 `libx.cpp、liby.cpp` 编译成 `libx.o、liby.o` 两个文件：

.. code-block:: shell
    :linenos:

    g++ -o main main.cpp libx.o liby.o

这个时候就会报出 `multiple definition of `foo()'` 的错误。但是如果把libx.o和liby.o分别打包成libx.a和liby.a用下面的方式编译：

.. code-block:: shell
    :linenos:

    g++ -o main main.cpp -L./ -lx -ly

这个时候编译不会报错，它会选择第一个出现的库，上面的例子中会选择libx中的foo。但是注意不是所有的情况都是这样的，由于链接是以.o为单位的，完全可以不用某个.o的时候才不会出错误，否则依然会出现 `multiple` 的错误，这种情况下的建议是查看一下这些函数的行为是什么样子，是否是一致的，如果不一致，还是想办法规避。如果是一致的话可以用 `-Wl,--allow-multiple-definition`  强制编译过去，这样会使用第一个碰到的库，但不推荐这样做。

可以通过　`g++ -o main main.cpp -L./ -lx -ly　-Wl,--trace-symbol=_Z3foov` 的命令查看符号具体是链接到哪个库中，也可以使用 `g++ -o main main.cpp -L./ -lx -ly　-Wl,--cref`　可以把所有的符号链接都输出(无论是否最后被使用)。

另外，对于一些定义在头文件中的全局常量，gcc和g++有不同的行为，g++中const也同时是static的，但gcc不是。如：

.. code-block:: cpp
    :linenos:

    //foo.h
    const int INTVALUE = 1000; 

有两个库 a和b，他们在生成的时候有使用到了 `INTVALUE` ，如果有一个程序main同时使用到了a库和b库，在链接的时候gcc编译的结果就会报错，但如果a和b都是g++编译的话结果却一切正常。这个原因主要是在g++中会把 `INTVALUE` 这种const常量当做static的，这样就是一个局部变量，不会导致冲突，但是如果是gcc编译的话，这个地方INTVALUE会被认为是一个对外的全局常量且是非static的，这个时候就会造成链接错误。

小提示：
1. 上面说了对于a库和b库出现同样符号的情况会有冲突， 但是在实际中有这么一种情况，a库定义的foo的接口，在有b库的情况下是一种行为，在没有b库的情况下又想要一种行为。为解决这个问题引入了弱连接的机制。可以看到在上述nm的输出中，有些符号前面有T标志，这个表示的是这个符号是一个强符号。如果看有W的表示，那么就表示这个符号是弱符号。如果有一个同名的库也有相同的符号并且是强连接，那么会报错（连接器不允许强符号冲突）。如果是弱连接，会存在先后顺序用谁的问题。glibc中的符号都是弱连接，我们可以在我们的程序中编写 `open、 write` 之类的函数去替换掉glibc中的实现。

如果我们要自己写弱连接的函数可以采用gcc扩展来表示一个符号是弱连接：

.. code-block:: cpp
    :linenos:

    __attribute__((weak)) const int func();

3. **动态链接**

对于静态库的使用，有下面几个问题：

1. 当我们需要对某一个库进行更新的时候，我们必须把一个可执行文件再完整的进行一些重新编译
#. 在程序运行的时候代码是会被载入机器的内存中，如果采用静态库就会出现一个库需要被copy到多个内存程序中，这个一方面占用了一定的内存，另一方面对于CPU的cache不够友好
#. 链接的控制，从前面的介绍中可以看到静态库的连接行为我们不好控制，做不到在运行期替换使用的库
#. 编译后的程序就是二进制代码，有些代码它们涉及到不同的机器和环境，假设在A机器上编译了一个程序X，把它直接放到B机器上去运行，由于A和B环境存在差异，直接运行X程序可能存在问题，这个时候如果把和机器相关的这部分做成动态库C，并且保证接口一致，编译X程序的时候只调用C的对外接口．对于一般的用户态的X程序而言，就可以简单的从Ａ环境放到Ｂ环境中。但如果是静态编译，就可能做不到这点，需要在Ｂ机器上重新编译一次

动态链接库在linux被称为共享库（shared library，下文提到的共享库和动态链接库都是指代shared library），它主要是为了解决上面列出静态库的缺点而提出的。

- 共享库的使用
    共享库的使用主要有两种方式，一种方式和.a的静态库类似由编译器来控制，其实质和二进制程序一样都是由系统中的载入器(ld-linux.so)载入，另一种是写在代码中，由我们自己的代码来控制。\

以上述的例子：

.. code-block:: shell
    :linenos:

    g++ -shared -fPIC -o libx.so libx.cpp

编译的时候和静态库类似，只是加上了 `-shared -fPIC` ，将输出命名改为.so。然后和可执行文件链接.a一样，都是：

.. code-block:: shell
    :linenos:

    g++ -o main main.cpp -L./ -lx

这样main就是调用 `libx.so` ，在运行的时候可能会出现找不到libx.so的错误，这个原因是由于动态的库查找路径的问题，动态库默认的查找路径是由 `/etc/ld.so.conf` 文件来指定，在运行可执行文件的时候，按照顺会去这些目录下查找需要的共享库。我们可以通过环境变量 `LD_LIBRARY_PATH` 来指定共享库的查找路径（注：LD_LIBRARY_PATH的优先级比ld.so.conf要高)。命令上运行 `ldd ./main` 我们可以看到这个二进制程序在运行的时候需要使用的动态库，例如：

.. code-block:: shell
    :linenos:

        linux-vdso.so.1 =>  (0x00007fffda6db000)
        libstdc++.so.6 => /lib64/libstdc++.so.6 (0x00007f71f2146000)
        libm.so.6 => /lib64/libm.so.6 (0x00007f71f1e43000)
        libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f71f1c2d000)
        libc.so.6 => /lib64/libc.so.6 (0x00007f71f186c000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f71f24d0000)

这里列出了main所需要的动态库, 如果有看类似 `libx.so=>no found` 的错误，就意味着路径不对，需要设置LD_LIBRARY_PATH来指定路径。

小提示：

1. 有一个特殊的环境变量 `LD_PRELOAD` ，可以强行替换共享库中运行的符号。`export LD_PRELOAD= "xxx.so"` ，如果程序运行过程中遇到了和 `xxx.so` 中 同名的符号，这个时候程序会使用到xxx.so中的符号。

- 手动载入共享库
    除了采用类型于静态库的方式来使用动态库，我们还可以通过由代码来控制动态库的使用。这种方式允许应用程序在运行时加载和链接共享库，主要有下面的四个接口：

.. code-block:: cpp
    :linenos:

    //载入动态链接库
    void *dlopen(const char *filename, int flag); 

    //获取动态库中的符号
    void *dlsym(void *handle, char *symbol); 

    //关闭动态链接库
    void dlclose(void *handle); 

    //输出错误信息
    const char *dlerror(void); 

看下面的例子：

.. code-block:: cpp
    :linenos:

    typedef int foo_t();

    foo_t * foo = (foo_t*) dlsym(handle, "foo"); 

通过上面的方式我们可以载入符号 `foo` 所对应的地址，然后通过强制类型转换给一个函数指针，当然这里函数指针的类型需要和符号的原型类型保持一致，这些一般是由共享库所对应的头文件提供。这里要注意一个问题，在dlsym中载入的符号表示是和我们使用nm库文件所看到符号表要保持一致，这里就有一个前面提到的gcc和g++符号表的不同，一个 `int foo()` ，如果是g++编译，并且没有extern "C"导出接口，那么用dlsym载入的时候需要用　`dlsym(handle, "_Z3foov")` 方式才可以载入函数 `int foo()` ，所以建议所以的共享库对外接口都采用　`extern "C"` 的方式导出纯C接口对外使用，这样在使用上也会比较方便。

dlopen 的flag 标志可以选择　`RTLD_GLOBAL/RTLD_LOCAL/RTLD_NOW/RTLD_LAZY` 。 `RTLD_NOW\RTLD_LAZY` 只是表示载入的符号是一开始就被载入还等到使用的时候被载入，对于多数应用而言没有什么特别的影响。这两个标志都可以通过 `|` 和 `RTLD_GLOBAL或RTLD_LOCAL` 一起连用。这里主要是说明 `RTLD_GLOBAL` 的功能，考虑这样的一个情况: 我们有一个main.cpp，调用了两个动态库 `liba.so` 和　`libB` ，假设liba中有一个对外接口叫做 `testA` ，在main.cpp可以通过dlsym获取到 `testA` 的指针进行使用。但是对于libb中的接口，它是看到不liba中的接口的，使用testA是不能调用到liba中的testA的，但是如果在dlopen打开liba.so的时候，设置了RTLD_GLOBAL这个选项，就可以把liba.so中的接口升级为全局可见, 这样在libb中就可以直接调用liba中的testA,如果在多个共享库都有相同的符号，并且有RTLD_GLOBAL选项，那么会优先选择第一个。另外这里注意到一个问题，RTLD_GLOBAL使的动态库之间的对外接口是可见的，但是动态库是不能调用主程序中的全局符号，为了解决这个问题， gcc引入了一个参数 `-rdynamic` ，在编译载入共享库的可执行程序的时候最后在链接的时候加上 `-rdynamic` ，会把可执行文件中所有的符号变成全局可见，对于这个可执行程序而言，它载入的动态库在运行中可以直接调用主程序中的全局符号，而且如果共享库（自己或者另外的共享库 使用RTLD_GLOBAL打开) 中有同名的符号，会选择可执行文件中使用的符号，这在一些情况下可能会带来一些莫名其妙的运行错误。

小提示：

1. `/usr/sbin/lsof -p $pid` 可以查看到由$pid在运行期所载入的所有共享库
2. 共享库无论是通过dlopen方式载入还是载入器载入，实质都是通过mmap的方式把共享库映射到内存空间中去。mmap的参数 `MAP_DENYWRITE` 可以在修改已经被载入某个进程文件的时候阻止对于内存数据的修改，由于现在内核中已经禁用这个参数，直接导致的结果就是如果对mmap的文件进行修改，这个时候的修改会被直接反映到已经被mmap映射的空间上。由于内核的不支持，使得共享库不能在运行期进行热切换，共享库在更新的时候需要由载入的程序通过一些外部的方式来判断，主动使用dlclose，并且dlopen 重新载入共享库，如果是载入器载入那么需要重启程序。另外这里的热切换指的是直接copy覆盖原有的共享库，如果是采用mv或者软连接的方式那么还是安全的，共享库被mv后不会影响原来的已经载入它的程序。
3. g++加上 `-rdynamic` 参数实质上相当于ld链接的时候加上 `-E或者--export-dynamic` 参数，效果与 `g++ -Wl,-E` 或者 `g++ -Wl,--export-dynamic` 的效果是一样的。

- 静态库和动态库的混合编译
    一般库都是以静态库的方式提供，但是也有出于运维和升级的考虑使用了动态链接库，这样不可避免的出现了大量的静态库与动态库的混合使用，经常会出现一些奇怪的错误，使用的时候需要有所关注。对于一般情况下，只要静态库与共享库之间没有依赖关系，没有使用全局变量（包括static变量)，不会出现太多的问题，但是偶尔也会因为库代码设计上的一些疏忽导致出现问题。如：一些基础库中的变量或函数，虽然没有通过.h文件公开，但是还是采用了extern的方式被其他的.c文件使用(这里涉及到一个问题就是一个源码中的变量或接口要被同一个库中其它地方使用，只能被extern，但extern 后就意味着可以被其它任意使用这个库的程序看到和使用, 无论是否在对外接口中声明), 还有个别接口可以使用static但没有使用static。导致升级后（如删除了extern的符号）导致链接错误。因此，在编写动态库的过程中，可以static的函数即使没有暴露在头文件也需要尽量static，避免和外界冲突。那种没有对外公开接口就无所谓加不加static的观点是存在一定风险的。

小提示：

1. 有些程序使用 `using namespace {}` 这样的匿名命名空间来规避冲突的问题，从编译器角度而言，在代码中使用确实不会产生冲突。不过采用dlopen的方式却还是可以通过强制获取符号的方式运行在共享库中使用 `using namespace {}` 包含起来的函数，但static的函数是不能被dlopen方式强制获取的。

a. 地址无关代码
    在64位下编译动态库的时候，经常会遇到下面的错误：

.. code-block:: shell
    :linenos:

    /usr/bin/ld: /tmp/ccQ1dkqh.o: relocation R_X86_64_32 against 'a local symbol' can not be used when making a shared object; recompile with -fPIC

提示说需要-fPIC编译，然后在链接动态库的地方加上-fPIC的参数编译结果还是报错，需要把共享库所用到的所有静态库都采用 `-fPIC` 编译一边才可以成功的在64位环境下编译出动态库。这里的-fPIC指的是地址无关代码。

这里首先先说明一下装载时重定位的问题，一个程序如果没有用到任何动态库，那么由于已经知道了所有的代码，那么装载器在把程序载入内存的过程中就可以直接安装静态库在链接的时候定好的代码段位置直接加载进内存中的对应位置就可以了。但是在面对动态的库的时候 ，这种方式就不行了。假设需要载入共享库A，但是在编译链接的时候使用的共享库和最后运行的不一定是同一个库，在编译期就没办法知道具体的库长度，在链接的时候就没办法确定它或者其他动态库的具体位置。另一个方面动态库中也会用到一些全局的符号，这些符号可能是来自其他的动态库，这在编译器是没办法假设的（如果可以假设那就全是静态库了)。基于上面的原因，就要求在载入动态库的时候对于使用到的符号地址实现重定位。在实现上在编译链接的时候不做重定位操作，地址都采用相对地址，一但到了需要载入的时候，根据相对地址的偏移计算出最后的绝对地址载入内存中。但是这种采用装载时重定位的方式存在一个问题就是相同的库代码（不包括数据部分）不能在多个进程间共享（每个代码都放到了它自己的进程空间中）,这个失去了动态库节省内存的优势。为了解决这个问题，ELF中的做法是在数据段中建立一个指向那些需要被使用(内部的位置无关简单采用相对地址访问就可以实现)的地址列表(也被称为全局偏移表，Global offset table, GOT)。可以通过GOT相对应的位置进行间接引用。对于32位环境来说，编译时是否加上-fPIC, 都不会对链接产生影响，只是一份代码的在内存中有几个副本的问题(而且对于静态库而言结果都是一样的)。但在64位的环境下装载时重定位的方式存在一个问题就是在我们的64位环境下用来进行位置偏移定位的cpu指令只支持32位的偏移, 但实际中位置的偏移是完全可能超过64位的,所以在这种情况下编译器要求用户必须采用-fPIC的方式进行编译的程序才可以在共享库中使用。从理论上来说-fPIC由于多一次内存取址的调用，在性能上会有所损失。不过从目前的一些测试中还无法明显的看出加上-fPIC后对库的性能有多大的损失，这个可能和现在使用的机器缓存以及大量寄存器的存在相关。

小提示：

1. -fPIC与-fpic。上面的介绍可以看到，gcc要使用地址无关代码加上-fPIC即可，但是在gcc的手册中我们可以看到一个-fpic(区别在一个大写一个小写)的参数，从功能上来说它们都是一样的。-fpic在一些特定的环境中（包括硬件环境)可以有针对性的进行优化，产生更小更快的代码，但是由于受到平台的限制，如编译环境、开发环境、运行环境都不完全统一的情况下面使用fpic有一定未知的风险，所有决大多数情况下我们使用-fPIC来产生地址无关代码。
2. 共享内存效率。共享内存在只读的情况下性能和读普通内存是一样的(如果不算第一载入的消耗），而且由于是多个进程共享对cpu cache还显的相对友好。

- 同时存在静态库和动态库
    前面提到编译动态库的时候有提到编译动态库可以像编译静态库那样采用 `-Lpath -lxx` 的方式进行，但这里存在一个问题，如果在path目录下既有动态库又有静态库的时候的行为又是什么样地？事实上在这种情下，链接器优先选择采用动态库的方式进行编译。比如在同一目录下存在libx.a和libx.so，那么在链接的时候会优先选择libx.so进行链接。为了能够控制动态库和静态库的编译, 有下面的几种方式：

a. 直接使用要编译的库
    在前面也提到了在编译静态库的时候有三种方式：1、目标文件.o直接使用；2、静态库文件.a直接编译；3、采用 `-L -l` 方式进行编译

编译的时候如果不采用 `-Lpath -lxx` 的方式进行编译, 而且直接写上 `path/libx.a` 或者 `path/libx.so` 进行编译，那么在链接的时候就是使用我们指定的.a或者.so进行编译不会出现所谓的动态库优先还是静态库优先的问题。但这个方案需要知道编译库的路径。

b. --static参数
    在gcc的编译的时候加上 `--static` 参数，这样在编译的时候就会优先选择静态库进行编译，而不是按照默认的情况选择动态库进行编译。不过使用 `--static` 参数会带来另外的问题，不推荐使用，主要会带来下面的问题：

    1. 如果只有动态库，而不存在同名的静态库，链接的时候也不会报错，但在运行的时候可能会出现错误 `/lib/ld64.so.1: bad ELF interpreter:` 
    2. 由于程序本身在运行的需要系统中一些库的支持，包括libc, libm, phtread等库，在采用 `--static` 编译方式之后，链接的就是这些库的静态编译版本(glibc还是提供了静态编译的版本)，我们等于使用的是编译机上的库，但是我们的运行环境可能和编译机有所不同，glibc这些动态库的存在本身的目的就是为了能让在一台机器上编译好的库能够比较方便的移到另外的机器上，程序本身只需要关注接口，至于从接口到底层的部分由每台机器上的.so来处理。另外就是glibc --static编译可能会产生下面的warning:

.. code-block:: shell
    :linenos:

    warning: Using 'getservbyport_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking

这个主要原因是由于 `getservbyport_r` 这样的接口还是需要动态库的支持才可以运行，许多glibc的函数都存在这样的问题，特别是网络编程的接口中是很常见的。另外，还有一些其他方面的问题：

1. 对一些第三方工具不友好，类似valgrind检查内存泄露为了不在一些特殊的情况下误报, 它需要用动态库的方式替换glibc中的函数，如果静态编译那么valgrind就无法替换这些函数，产生误报甚至无法报错。tcmalloc在这种情况下也不能支持。
2. 目前64位环境中使用的pthread库，如果使用的是动态库那么采用的是ntpl库，如果是静态库采用的linuxthread库，使用--static 会导致性能下降。
3. --static之后会导致代码大小变大，对cpu代码cache不友好，浪费内存空间，不过对于小代码问题也不大。

早期有一些测试表明在32位的环境下，采用--static全部使用静态库可以使程序性能有1%~3%的提高，这个主要原因在于-fPIC产生的二次寻址问题导致(glibc那些库都是采用了-fPIC的方式进行编译)。但是如果机器缓存大，代码小，这种的性能提高实在是很有限了。在运行了多个程序的机器上反倒可能由于cache不友好有反效果。另外注意就是原来在32位下有性能优势当升级到64位机器上可能就没有优势了。

c. 链接参数控制
    链接器中提供了 `-dn -dy` 参数来控制使用的是动态库还是静态库，-dn表示后面使用的是静态库，-dy表示使用的是动态库。如：

.. code-block:: shell
    :linenos:

    g++ -Lpath -Wl,-dn -lx -Wl,-dy -lpthread

这样如果在path路径下有libx.so和libx.a这个时候只会用到libx.a。注意在最后的地方如果没有 `-Wl,-dy` 让后面的库都使用动态库，可能会报出 `cannot find -lgcc_s` 的错误，这是由于glibc的.a库和.so库名字不同，--static会自动处理，但是 -Wl,-dy却不会去识别这个问题。

小提示：

1. 如果使用 `--static` ，由于 `-dy` 的使用导致后面的库都是共享库（dy强制屏蔽了静态库），这个时候编译出来的程序和只有动态库的情况下强制使用 `--static` 编译一样都会报错。

- 运行报错 `undefined reference to `xxx()'` 
    对于动态链接库，实际的符号定位是在运行期进行的。在编译.so的时候，如果没有把它需要的库和他一起进行联编，比如libx.so需要使用liby.a，但是忘记在编译libx.so的时候加上-ly的话，在编译libx.so的时候不会报错，因为这个时候libx.so被认为是一个库，它里面存在一些不知道具体实现的符号是合法的，是可以在运行期指定或者编译另外的二进制程序的时候指定。如果是采用　`g++ -Lpath -lx` 的方式进行编译，链接器会发现所需要的liby.a的符号表找不到从而报错，但是如果是程序采用dlopen的方式载入，由于是运行期，这个程序在这个地方就直接运行报错了。另外还有一种情况就是一个对外的接口在动态库中已经声明定义了，但是忘记实现了，这个时候也会产生类似的错误。

    如果在运行期报出这样的错误，就要注意是否是由于某些库没有链接进来或者某些接口没有实现的原因产生。

- 多个so以及主程序同时使用相同的函数
    举例来说：有一个程序，它通过dlopen的方式调用了一个.so文件。在这个主程序中和.so中都使用了日志库，主程序中使用 `init_log` （或其他类似函数）做初始化日志，在.so中没有用 `init_log` 日志．这个时候发现，主程序中的日志正常输出，但.so中的日志却直接输出到了标准出错（或输出错误）。    这个问题的原因在前面的其实已经提到了，在默认情况下主程序中使用的接口对于.so是不可见的，.so所在的代码空间与主程序的代码空间是隔离的，这个时候.so调用的 `write_log` 其实是没有经过 `init_log` 的那块代码空间，由于日志库使用了一些static变量或全局变量，只有在 `write_log` 以及 `init_log` 都是在同一块空间上的时候才会起作用。

    这个问题的一个最简单的解决方案是：

    1. 在主程序的链接的时候加入-rdynamic，仍然链接liblog.a库
    2. 编译动态链接库时，不加链接liblog.a库

    其实动态库这里是否链了liblog.a已经不重要了，在有-rdynamic的情况下，.so中如果有与主程序同名的函数那么会优先调用主程序中的函数，动态库不链接liblog.a倒是可以省点空间。但是这种方式在某些情况还是不能完全解决问题：

    假设有A.so, B.so，主程序main，在A.so中调用了 `init_log` ，B.so中没有调用 `init_log` ， 但调用了 `write_log` 。在主程序中没有调用log库中的任何接口和使用任何变量。这种情况下即时使用了-rdynamic还是会导致在A.so中正常输出日志，但在B.so中却把日志输出到标准出错（或输出异常）。这个问题的主要原因在于，gcc在链接的时候是以.o为单位的，如果一个.o中的符号没有被外部所使用，那么在链接的时候就不会把这个.o中的符号给链接进.so或者二进制程序中。在上面的问题中主程序里面没有调用到日志库中的任何符号，所以在链接的时候就不会把log库中的 `init_log` 和 `write_log` 给链接进主程序中，这个时候即使有 -rdynamic也是做不到让.so中的动态链接库都使用。

    这个问题一般有下面几种方案：
    1. 载入A.so的时候使用RTLD_GLOBAL参数，把A.so中的所有的符号都变成对外可见，这样A.so和B.so的 `write_log` 都在一块代码空间中了
    2. 编译主程序的时候链接log库的地方由-llog改为　`-Wl,--whole-archive -llog -Wl,--no-whole-archive` ，同时加上 `-rdynamic` 。 `-Wl, --whole-archive` 是链接参数，它表示把log库的中所有的符号都链接进主程序中，而不管主程序是否调用了log库中的符号。 `-Wl,--no-whole-archive` 表示后面的链接取消 `--whole-archive` 的行为，毕竟其他的库没有必要采用这种方式全部链接进来。
    3. 在主程序中随便调一下log库中的符号，比如可以先随便 `init_log` 一下，然后 `close_log`，后面再进行动态库调用
    4. 把liblog.a用 `ar x`　命令还原成多个.o文件，采用直接链接的方式使用log.o

    上面的几个问题的产生主要还在于静态链接和动态链接混用，而两种链接方式又存在不一样的地方。事实上如果我们把log库采用动态链接库的方式编译成liblog.so，采用前面的方式在编译期链接liblog.so，并且设置LD_LIBRARY_PATH，上面的2个问题都不会存在。编译期使用的.so，是全局可见的，不需要 `-rdynamic` 也可以被dlopen的动态库所用到，由于是动态链接库，所以包含了所有的符号，不会像静态库那样只包含了所用到的.o中的符号． 事实上这也是多数第三方程序的解决方案。

    主程序中使用 `-rdynamic` 会对后续的升级造成一些麻烦:

    1. 加上 `-rdynamic` 后，像日志库这样的基础如果需要升级，那么就必须要升级主程序，使用的.so无论如何升级，其所用到的 `write_log` 都是主程序中的
    2. 主程序中除了日志库，还会有其他库或者函数的存在，这些函数如果不是static的就有可能与dlopen打开的so中的函数混到一起，造成困惑
    3. 如果.so中需要打印它自己的日志，那样需要log本身功能支持才可以实现，而不能简单的使用write_log来实现

    但是如果主程序中没有使用 `-rdynamic` ，那么又有下面的这些麻烦：

    1. dlopen打开的动态库日志是打印自己的，不能和主程序统一在一起
    2. 如果.so的程序和主程序open的是同一个日志，这相当于多进程打日志, 那必须要log库的支持
    3. 如果主程序中用 `dlopen+RTLD_GLOBAL` 的打开了某个.so，日志的问题就可能影响到其他的.so中的调用

    这里对于类似日志库这种需要全局状态变量支持的库提出另外方案：

    1. 编译一个专门的.so，这个.so中包括了其它.so中所需要的所有和全局变量相关的接口 
    2. 主程序不使用 `-rdynamic` 编译，但打开上面的.so的时候，采用RTLD_GLOBAL方式，并且是第一个打开 
    3. 除了打开第一个 .so，其它的.so都不使用RTLD_GLOBAL方式，并且在编译的时候都不把和第一.so相关的库联编 
    4. 第一个.so的升级需要保证没有其它.so在运行才可以dlclose，重新dlopen

    这个问题首先需要明确需求，到底是希望每个.so打自己独立的日志还是和主线程统一。

    这里要注意另外一个问题就是如果log日志库中引入一些extern出来的全局变量。在采用dlopen的时候，对于一般符号，一般都是主程序和动态库在两块空间中， 但是对于使用extern出来的变量主程序和动态库都是在一块空间中（注：由于32位下不用-fPIC也可以编译so，在没有-fPIC的情况也是分开的，但是由于64位一定要-fPIC所以一定会出现同一块空间的问题），对于这个问题的解决方案是在动态库链接的时候加上 `-Wl,-Bsymbolic` 参数将动态库的空间和主程序的空间强行分开。

    上面有提到编译动态链接库时，不加链接liblog.a库，但主程序使用-rdynamic, 这里主要是为了避免使用到了不同的log库导致调用了一些不同的内部符号，导致出现另外的麻烦。对于动态库中的日志建议采用下面的几个方案:
    1. 动态库完全打自己的，日志，编译二进制程序不要用 `-rdynamic` ， 动态库链接的编译加上 -Wl,-Bsymbolic 参数，链接log, 在动态库中自己 `init_log` ，自己控制等级 
    2. 动态库不链接log, 编译二进制程序用 `-rdynamic` ，这样可以正确的使用主程序中的日志库，也规避了版本不一致带来的问题，但是这样失去了对于动态库日志的控制， 而且存在升级的不便，日志的升级是由主程序控制的。

    小提示：

    1. 在运行期可以通过设置环境变量LD_DEBUG查看每个符号具体链接到了什么地方，每个符号具体的查找过程和绑定过程。可以这样使用；

.. code-block:: shell
    :linenos:

    export LD_DEBUG=help

随便运行一个程序就可以看到对于LD_DEBUG的使用说明。以下则看到整个装载过程：

.. code-block:: shell
    :linenos:

    export LD_DEBUG=files

    ./main

3. **版本控制**
    系统中存在了大量的动态库和静态库，并且每个库都会随着库的升级和更新，形成各种的版本，这些版本之间又存在了各种各样的兼容或者不兼容的问题。linux中是如何维护和管理这些库的？这里介绍了linux在这方面所作的一些工作。下面的这些都是基于我们现在使用的64位开发环境中的情况, 与32位的老版本存在了一定程度上的不兼容。

- 命名
    在linux系统中对于一个共享库的命名一般是　`libname.so.x.y.z` 。不过在linux中　也有不少不遵守上面的命名的，比如glibc的动态库叫libc-2.3.5.so, 版本号在.so前面。这里又存在了另一个问题，由于版本号和命名捆绑在一起，那么当库升级的时候有怎么把版本号给对应上呢？

- 编译和载入的版本
    先看一下pthread库在系统中的情况，(下面是以64位开发机为例,32位路径有所不同其它都一样)。在 `/usr/lib64/`　中可以找到 `libpthread.so` ，cat 一下可以看到这其实是一个文本文件：

.. code-block:: shell
    :linenos:

    /* GNU ld script
       Use the shared library, but some functions are only in
       the static library, so try that secondarily.  */
    OUTPUT_FORMAT(elf64-x86-64)
    GROUP ( /lib64/libpthread.so.0 /usr/lib64/libpthread_nonshared.a )

这个libpthread.so其实并不是什么共享库，它其实是一个ld的链接脚本，这个脚本的意思是，输出的是elf64-x86-64格式，使用的动态库是/lib64/libc.so.0，静态库是/usr/lib64/libc_nonshared.a，这样我们在编译的时候不用考虑使用的是哪一个版本的libpthread.so，也不需要靠它的动态库叫什么，静态库叫什么，只需要都是指定-lpthread就可以了，具体实际是哪个版本，交给脚本去处理。

再看 `/lib64/libpthread.so.0` ，其实这是一个软链接，它实际指向的是 `libpthread-2.17.so` ， `libpthread-2.17.so` 才是它真正使用的.so。pthread它通过这样的方式进行链接有什么作用呢？先随便写个使用了pthread的程序，然后用 `readelf -d` 查看，这时候可以看到pthread那一行指向的是 `libpthread.so.0` ，而不是 `libpthread-2.17.so` 。其实pthread这样处理主要是从版本的兼容性方面进行考虑。在我们编译的阶段通过ld脚本，统一了编译时候-l使用的命字，我们编译的时候不需要去考虑什么.so的版本号问题。编译完了实际指向的是 `libpthread.so.0`，而不是最后的 `libpthread-2.17.so` ，这样的好处在下面的几个方面:

1. 如果pthread升级了，比如升级后叫做libpthread-2.20.so，作为开发者可以保证它和 `libpthread-2.17.so` 是兼容的，那么我们可以大胆的把 `libpthread.so.0` 的软链接指向 `libpthread-2.20.so` ，这不会出现什么问题。
2. 如果 `libpthread-2.20.so` 与 `libpthread-2.17.so` 是不兼容的，那么我们可以新建立一个叫做 `libpthread.so.1` 的符号链接指向 `libpthread-2.20.so` ，这样老的程序在运行由于它认为自己使用的是 `libpthread.so.0` 而不会指向 `libpthread.so.1` ，而用新版本编译出来的程序会自动依赖到 `libpthread.so.1` ，而不会出现依赖了老的 `libpthread-2.17.so` 而导致不兼容。需要依赖老版本的程序在运行的过程中也不会出现因为依赖的库替换了不兼容的库导致出现问题。

- 符号版本
    上面的这个过程很好的解决了在同一台机器上编译和使用动态库的更新问题。但是还有一些问题上面的方式无法完全解决。比如现在的程序是使用了 `libpthread-2.20.so` 编译出来的程序，但是在运行的机器上只有 `libpthread-2.17.so` ，这个时候有2种选择：

    1. 警报，但让程序继续运行,这有可能会出core 
    2. 直接禁止运行

    现在的问题，很有可能我虽然用了新的库进行编译，但我只用到了老的接口，用 `libpthread-2.17.so` 就可以胜任我的工作，但无论警报也好还是直接禁止运行也好这些都显的不合适。为了能解决这个问题, linux在符号中引入了版本的机制。我们可以用 `nm /lib64/libc.so.6`  查看glibc中的符号表(我们32位环境中的glibc符号表被清空了，只能通过readelf进行查看)。我们可以看有不少接口被写成类似于 `tmpfile@@GLIBC_2.2.5` 的形式，在符号中带有版本号信息，这方式可以使程序在编译的时候记录下它编译的时候使用的共享库所对应的接口的版本号，这样如果共享库升级了，当程序载入共享库的时候会检查编译时记录下来的版本是否与当前共享库接口的版本是否兼容，如果兼容那么就可以正常运行，如果有不兼容的情况就在载入库的时候报错。这种机制尽可能的考虑高版本与低版本的兼容性问题，如果我们打开glibc的源码包，我们可以到许多目录下都有一个叫 `Versions` 的文件，这个文件就是用来描述各接口的兼容版本。

- 共享库可执行
    我们直接运行 `/lib64/libc.so.6` ，可以看到在运行后出现了一段的文字，表示了库的版本、作者、编译时间等信息。这种方式提供了一种给用户确认和了解动态库的方式。这种方式的实现也很简单，下面是一个demo： 

.. code-block:: cpp
    :linenos:

    //share.cpp
    #include <stdio.h>
    #include <stdlib.h>

    #if defined(__DATE__) && defined(__TIME__)
    const char* BUILT_DATE = __DATE__ " " __TIME__;
    #else
    const char* BUILT_DATE = "unknown";
    #endif

    #ifdef __SOVERSION__
    const char* VERSION = __SOVERSION__;
    #else
    const char* VERSION = "unknown";
    #endif

    #ifdef __cplusplus 
    extern "C" { 
    #endif

    /** @brief 使用的动态链接库, 使用ldd命令可确认**/
    #ifndef __i386
    #define LD_SO_PATH "/lib64/ld-linux-x86-64.so.2"
    #else 
    #define LD_SO_PATH "/lib/ld-linux.so.2" 
    #endif

    /* @brief 设置入口位置 */
    const char interp[] __attribute__((section(".interp"))) = LD_SO_PATH;

    /* @brief .so文件运行的入口函数 */
    void so_main()
    {
        //char buf[128];
        //这个可以规避由于-O2开关导致，__((section(".interp"))) 被优化没的问题
        //snprintf(buf, sizeof(buf), "interp: %p\n", interp); 

        printf("ld.so: %s\n", interp);  //所使用的加载器
        printf("svn: %s\n", "xxx/xxx/xxx"); //动态库svn路径
        printf("Brief: %s\n", "test for so"); //动态库简介
        printf("BuildDate: %s\n", BUILT_DATE);  //编译时间
        printf("Version: %s\n", VERSION); //版本
        exit(0);
    }

    #ifdef __cplusplus 
    }
    #endif

其中 `LD_SO_PATH` 表示了所使用的加载器，这里要注意32位和64位的区别，这里把过程简化了用宏 `__i386` 来判断32位与64位。 `section(".interp")` 设置了运行使用的载入器。 `so_main` 是运行程序的地方，这里写上供享编译的信息，当然这个地方可以换成别的什么名字，在编译的时候需要加上 `-Wl,-e,so_main` ，指明了动态库的实际的入口位置(这里是so_name, 也可以换成xxx)。采用的编译参数如下：

 .. code-block:: shell
    :linenos:

    g++ -shared -O2 -g -fPIC -D__SOVERSION__="\"1.0.0.0\"" -Wl,-e,so_main share.cpp -o libshare.so

在把生成的.o与共享的主程序链接到一起，就可以直接运行共享库了。

3. **总结和建议**
    上面介绍库(包括静态库和共享库)链接的过程，并对应其实现进行了分析，并且针对编译中出现的问题进行分析和解决。这对于我们使用库是有一定的帮助的。这里对于库的编写和使用提出一些建议：

- 静态库
    + 尽量不要使用--static参数，对于一些特殊的必须要使用.so的情况，可以考虑使用-Wl,-dn 的方式进行
    + 64位环境中编译加上-fPIC。虽然是静态库，但很可能会被用作共享库的一部分
    + 链接的时候注意链接的顺序，越是基础库越是在后面

- 共享库
    1. 开发
        1. 对外接口尽量使用基本类型，不要使用C++类，如果一定需要建议采用指针的方式
        2. 对外接口采用 `extern "C"` 的方式提供，不要直接使用一般的C++接口，这主要是从接口的方便性考虑，毕竟都不希望采用"_fooIV"这种形式的接口进行访问
        3. 共享库的生成文件需要带上我们的4位版本号，格式与linux的格式相同，如 libmylib.so.1.1.0.0
        4. 共享库需要能够自运行，运行需要输出版本号、编译时间、库的简单说明，DEMO见上文中共享库可执行部分. 输出格式建议：
            1. 采用printf输出，考虑到以后可能可以用脚本分析。输出格式参考DEMO的样式
        5. 小心使用 `-rdynamic` 参数，能够不使用就不要使用
        6. 尽量保证主程序的编译依赖与动态库的编译依赖相同，特别是在主程序代码中使用-rdynamic。

    2. 发布    
        动态库发布到特定目录下除了要有带版本号的.so，还需要同时有一个未带版本号的.so，比如在output/lib目录需要有 `libmylib.so.1.1.0.0` 和一个软链接 `libmylib.so` 指向 `libmylib.1.1.0.0` ，这里的 `libmylib.so` 软链接主要是给其它程序编译期使用的。

    3. 上线
        1. 严禁对于.so采取直接copy覆盖的方式。
        2. 更新.so, 可以采用两种方式：
            1. 软链接方式，程序运行使用的是 `libmylib.so` 软链接，上线的时候采用的是把 `libmylib.so` 链接指向 `libmylib.so.1.1.0.0` ，由于原来的程序还在，这样不会出现问题
            2. mv方式，旧的.so需要先mv成另外的文件名，然后再放入新的.so
        3. 需要确认.so已经被载入，由于.so的使用本身有2种方式，需要考虑下面两种情况：
            1. dlopen方式，这种重新载入可以适用于热切换，这个要求RD根据代码逻辑来控制，一般可以从日志看出
            2. LD_LIBRARY_PATH指定路径，这种情况一般第三方库的情况比较多，这个时候需要把程序重启
        4. 所有操作完毕之后，需要用 `/usr/sbin/lsof -p pid` 查看载入的动态库是否是我们需要的
        5. 不要在终端或者 `.bash_profile` 等全局环境中加入 `LD_LIBRARY_PATH` ，在启动需要.so的程序脚本中加入即可